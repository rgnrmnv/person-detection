## Проект для детекции людей на видео с использованием двух архитектур нейронных сетей: YOLOv8 и RT-DETR. 
Включает ByteTrack для отслеживания, детекцию маленьких объектов и фильтрацию дубликатов.

---

## Как запустить
1. Склонировать проект:
```bash
git clone https://github.com/rgnrmnv/person-detection.git
cd person-detection
```
2. Установить зависимости:
```bash
pip install -r requirements.txt
```
3. Запустить проект:
```bash
python run_final.py
```
4. Выбрать что запустить:
   - 1 - только YOLOv8 
   - 2 - только RT-DETR 
   - 3 - обе модели + сравнение 
5. Указать сколько кадров обработать 
6. Готово! Результаты будут в папке results/:
   - yolov8_final.mp4 - видео с детекциями YOLOv8
   - rtdetr_final.mp4 - видео с детекциями RT-DETR
   - benchmark_final.json - сравнение моделей

---



## Возможности

- Детекция людей с двумя разными архитектурами
- ByteTrack для отслеживания объектов
- Детекция маленьких объектов (тайлинг)
- Фильтрация дубликатов (advanced NMS)
- Бенчмаркинг и сравнение моделей
- Визуализация с bbox, confidence scores, tracking ID
- Поддержка CPU и GPU

---

## Структура проекта

```
├── run_final.py                   # Главный скрипт - запускает всё
├── inference.py                   # Детекция на видео
├── benchmark.py                   # Сравнение моделей
│
├── detectors/                     # Детекторы
│   ├── yolov8_detector.py
│   └── rtdetr_detector.py
│
├── tracking/                      # Трекинг
│   └── bytetrack.py
│
├── utils/                         # Утилиты
│   ├── video_utils.py            # Работа с видео
│   ├── visualization.py          # Визуализация
│   ├── metrics.py                # Метрики
│   ├── nms.py                    # Фильтрация дубликатов
│   └── multiscale_detection.py   # Детекция маленьких объектов
│
├── config/                        # Конфигурации
│   ├── yolov8_config.yaml
│   └── rtdetr_config.yaml
│
├── results/                       # Результаты
│   ├── yolov8_final.mp4
│   ├── rtdetr_final.mp4
│   ├── yolov8_metrics.json
│   ├── rtdetr_metrics.json
│   └── benchmark_final.json
│
├── crowd.mp4                      # Входное видео
├── yolov8m.pt                     # Веса YOLOv8
├── rtdetr-l.pt                    # Веса RT-DETR
│
├── README.md                      # Документация
└── requirements.txt               # Зависимости
```

---
### Ручной запуск одной модели
```bash
# YOLOv8
python inference.py --model yolov8 --input crowd.mp4 --tracking --small-objects

# RT-DETR
python inference.py --model rtdetr --input crowd.mp4 --tracking --small-objects

# Benchmark:
python benchmark.py --input crowd.mp4 --output results/benchmark.json
```

## Почему эти модели

#### YOLOv8 (Ultralytics)
Выбрана как основная модель для решения задачи. Это современный CNN-based детектор, который работает в один проход (one-stage). 

Преимущества:
- Быстрая обработка, подходит для real-time систем
- Хороший баланс точности и скорости
- Есть готовые оптимизации (TensorRT, ONNX)
- Широко используется в промышленности
- Простая интеграция

В проекте используется версия YOLOv8m (medium) - это компромисс между скоростью и точностью. Модель обучена на COCO датасете, который включает класс "person".

#### RT-DETR (Real-Time Detection Transformer)
Выбрана для сравнения как представитель новой архитектуры на базе трансформеров.

Преимущества:
- Использует attention mechanisms - лучше работает с перекрытиями
- Не требует NMS (Non-Maximum Suppression) - встроено в архитектуру
- Хорошо справляется с плотной толпой
- Показывает знание современных подходов (SOTA 2023-2024)

В проекте используется RT-DETR-l (large) для максимальной точности детекции.

#### Зачем ByteTrack
ByteTrack - это алгоритм отслеживания объектов (MOT - Multiple Object Tracking). Он присваивает каждому человеку уникальный ID и следит за ним между кадрами.

Это нужно чтобы:
- Сгладить детекции (убрать дрожание bbox)
- Посчитать уникальных людей
- Улучшить визуальное восприятие результата

#### Детекция маленьких объектов
Люди вдали на видео занимают мало пикселей, и стандартные детекторы их часто пропускают. Для решения этой проблемы используется метод тайлинга: кадр разбивается на перекрывающиеся фрагменты, детекция запускается на каждом фрагменте отдельно, потом результаты объединяются.

Это увеличивает время обработки, но значительно улучшает качество детекции удаленных объектов.

---

## Результаты и рекомендации

### Что получилось

**YOLOv8:**
- Стабильная производительность (высокий FPS)
- Высокая средняя уверенность детекций (около 0.61)
- Мало ложных срабатываний
- Может пропускать людей в плотной толпе (около 30% при сильном перекрытии)
- Хорошо работает в реальном времени даже на CPU

**RT-DETR:**
- Находит больше объектов (почти в 2 раза больше детекций)
- Лучше работает с перекрытиями благодаря attention mechanism
- Меньше пропусков в плотной толпе
- Ниже средняя уверенность (около 0.51 vs 0.61 у YOLOv8)
- Медленнее обрабатывает видео

#### Какую модель выбрать

**Для production систем:** YOLOv8
- Быстрая обработка
- Стабильные детекции
- Легко оптимизировать (TensorRT)
- Подходит для real-time

**Для максимальной точности:** RT-DETR
- Меньше пропусков
- Лучше с плотной толпой
- Можно использовать как вторую модель для проверки

#### Как можно улучшить

**1. Ансамблирование**
Комбинировать предсказания YOLOv8 и RT-DETR. YOLOv8 дает быстрые и точные детекции, RT-DETR добавляет те объекты, которые YOLOv8 пропустила. Это увеличит mAP на 3-7% и уменьшит количество пропусков.

**2. Fine-tuning**
Дообучить модели на специализированных датасетах для толпы (например, CrowdHuman, WIDER Person). Общие модели обучены на COCO где сцены разнообразные, а для плотных толп нужна специализация.

**3. Адаптивный порог**
Сейчас используется фиксированный порог уверенности (0.25-0.30). Можно сделать динамическую подстройку в зависимости от плотности кадра: в простых сценах порог выше (меньше ложных срабатываний), в сложных - ниже (меньше пропусков).

**4. Тестирование на разных разрешениях**
Запускать детекцию на нескольких масштабах изображения и объединять результаты. Это особенно помогает для объектов разного размера в одном кадре.

